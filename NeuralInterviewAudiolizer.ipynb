{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralInterviewAudiolizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1LVLRNPpstjRBHwxu7zGCKFWZEuLmr4gq",
      "authorship_tag": "ABX9TyNCwZpdW32WLm/TH7QovLUS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olaviinha/NeuralInterviewAudiolizer/blob/main/NeuralInterviewAudiolizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5VtWDrgJzuP"
      },
      "source": [
        "#<font face=\"Trebuchet MS\" size=\"6\">Neural Interview Audiolizer <font color=\"#999\" size=\"3\">WaveNet Text-to-Audio Dialogue Generator</font><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><a href=\"https://github.com/olaviinha/WavenetDialogueGenerator\" target=\"_blank\"><font color=\"#999\" size=\"4\">Github</font></a><font color=\"#999\" size=\"4\">&nbsp;&nbsp;&nbsp;|&nbsp;&nbsp;&nbsp;</font><font size=\"3\" color=\"#999\"><a href=\"https://inha.se\" target=\"_blank\"><font color=\"#999\">O. Inha</font></a></font></font>\n",
        "\n",
        "This notebook turns a textual dialogue between two individuals (e.g. an interview, a chat) from a .txt file into audio dialogue using [Google Cloud Text-to-Speech API](https://cloud.google.com/text-to-speech). It uses two selectable WaveNet voices.\n",
        "\n",
        "<h3>Please note</h3>\n",
        "\n",
        "- Using this notebooks requires access to Google's Text-to-Speech API with an API key. See [this page](https://cloud.google.com/text-to-speech/docs/quickstart-client-libraries#before-you-begin) for more information on how to obtain required credentials.\n",
        "- At the time of writing this notebook, some of the required packages to use Text-to-Speech Python API are deprecated in Google Colaboratory environment by default. Since package upgrading requires runtime restart and all that, instead this notebook currently uses Text-to-Speech API's command line interface with `curl`.\n",
        "\n",
        "<h3>Accepted formats</h3>\n",
        "\n",
        ".txt file containing the dialogue must be in one of the following formats. If your dialogue material is a copy-paste from the interwebs, make sure to clean it up first to meet one of the following formats.<br><br>\n",
        "\n",
        "<hr size=\"1\" color=\"#666\"/>\n",
        "\n",
        "### `dialogue_with_names`\n",
        "\n",
        "In this format, character `:` is used to determine when the person speaking changes. Hence, `:` should not appear anywhere else in the text. Empty lines are ignored. Names (whatever comes before `:` in each line) are ignored.\n",
        "\n",
        "<font color=\"#dd6\">_John: Hello Doe!_<br> _Doe: Well, hello there John._<br>_How are you?_<br>_John: I'm good thank you, and you?_<br>_Doe: Fantastic._</font>\n",
        "\n",
        "<hr size=\"1\" color=\"#666\"/>\n",
        "\n",
        "### `question_and_answer`\n",
        "\n",
        "In this format, empty lines are used to determine when the person speaking changes, i.e. there must be an empty line in the text after one of the individuals is done talking and the other should start talking.\n",
        "\n",
        "<font color=\"#dd6\">_Hello Doe!_<br><br> _Hi!_<br><br>_How are you?_<br>_What's new?_<br><br>_Struggling as usual, nothing new._<br><br>_What do you think about politics?_<br><br>_Not interested..._<br>_Like no thanks._</font>\n",
        "\n",
        "<hr size=\"1\" color=\"#666\"/>\n",
        "\n",
        "<h3>Tips</h3>\n",
        "\n",
        "- You can test what the voices sound like in advance [here](https://cloud.google.com/text-to-speech#section-2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIwpvYHfN3tC",
        "cellView": "form"
      },
      "source": [
        "#@title #Setup\n",
        "#@markdown This cell needs to be run only once. It will mount your Google Drive and setup prerequisities.\n",
        "\n",
        "#@markdown <small>Path to Google Service Account Key file (json) located in your Google Drive.</small>\n",
        "credentials_file = \"gc_credentials.json\" #@param {type:\"string\"}\n",
        "import os\n",
        "from google.colab import output\n",
        "\n",
        "pip_packages = 'google-api-core google-api-python-client google-auth-httplib2 google-auth-oauthlib google-cloud-texttospeech soundfile'\n",
        "\n",
        "# inhagcutils\n",
        "if not os.path.isfile('/content/inhagcutils.ipynb'):\n",
        "  %cd /content/\n",
        "  !pip -q install --upgrade import-ipynb {pip_packages}\n",
        "  #!apt-get install sox\n",
        "  !curl -s -O https://raw.githubusercontent.com/olaviinha/inhagcutils/master/inhagcutils.ipynb\n",
        "import import_ipynb\n",
        "from inhagcutils import *\n",
        "\n",
        "# Mount Drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "# Drive symlink\n",
        "if not os.path.isdir('/content/mydrive'):\n",
        "  os.symlink('/content/drive/My Drive', '/content/mydrive')\n",
        "  drive_root_set = True\n",
        "drive_root = '/content/mydrive/'\n",
        "\n",
        "dir_tmp = '/content/tmp/'\n",
        "create_dirs([dir_tmp])\n",
        "\n",
        "import os, json, soundfile\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=drive_root+credentials_file\n",
        "\n",
        "tmp = '/content/tmp/'\n",
        "global_sr = 24000\n",
        "\n",
        "def writeFile(file, content):\n",
        "  f = open(file, 'w')\n",
        "  f.writelines(content)\n",
        "  f.close()\n",
        "\n",
        "def appendTxt(txt_file, content):\n",
        "  txt = open(txt_file, 'a+') \n",
        "  txt.writelines(content+'\\n')\n",
        "  txt.close()\n",
        "\n",
        "def generate_silence(duration, sr=global_sr):\n",
        "  content = [0]*librosa.time_to_samples(duration, sr=sr)\n",
        "  silence = np.array([content, content], dtype=np.float32)\n",
        "  return silence\n",
        "\n",
        "def save(audio_data, save_as='frank', sr=global_sr):\n",
        "  if save_as=='frank':\n",
        "    global bpm\n",
        "    timestamp = datetime.datetime.today().strftime('%Y%m%d-%H%M%S')\n",
        "    save_as = save_as+'_'+rnd_str(4)+'_'+timestamp+'__'+bpm+'bpm.wav'\n",
        "  soundfile.write(save_as, audio_data.T, sr)\n",
        "\n",
        "# Fetch voices\n",
        "voices_json = !curl -H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) -H \"Content-Type: application/json; charset=utf-8\" \"https://texttospeech.googleapis.com/v1/voices\"\n",
        "voices = json.loads(\"\\n\".join(voices_json))\n",
        "en_voices = []\n",
        "for voice in voices['voices']:\n",
        "  if \"en-\" in voice['languageCodes'][0] and \"Wavenet\" in voice['name']:\n",
        "    en_voices.append([voice['languageCodes'], voice['name'], voice['ssmlGender']])\n",
        "\n",
        "output.clear()\n",
        "op(c.ok, 'FIN.')\n",
        "\n",
        "# Update voice lists (copy-paste to dropdown)\n",
        "# for voice in en_voices:\n",
        "#   print('\"'+voice[1]+'_'+voice[2]+'\",', end='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6bA2qunBGoQ",
        "cellView": "form"
      },
      "source": [
        "#@title #Generate audio dialogue\n",
        "\n",
        "#@markdown <small>Path to .txt file containing the dialogue, located in your Google Drive.</small>\n",
        "dialogue_txt = \"\" #@param {type:\"string\"}\n",
        "format = \"question_and_answer\" #@param [\"dialogue_with_names\",\"question_and_answer\"]\n",
        "#@markdown <small>Add this much random variation to the pauses. `pX_pause` sliders determine how long pause there will be **after** that person is done talking.</small>\n",
        "pause_variation = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "## #@markdown <small>Use cURL instead of Python API.</small>\n",
        "## use_curl = True #@param {type:\"boolean\"}\n",
        "use_curl = True\n",
        "\n",
        "#@markdown <hr size=\"1\" color=\"#666\"/>\n",
        "\n",
        "#@markdown ###Individual #1\n",
        "p1_voice = \"en-AU-Wavenet-B_MALE\" #@param [\"en-GB-Wavenet-F_FEMALE\",\"en-IN-Wavenet-D_FEMALE\",\"en-AU-Wavenet-A_FEMALE\",\"en-AU-Wavenet-B_MALE\",\"en-AU-Wavenet-C_FEMALE\",\"en-AU-Wavenet-D_MALE\",\"en-GB-Wavenet-A_FEMALE\",\"en-GB-Wavenet-B_MALE\",\"en-GB-Wavenet-C_FEMALE\",\"en-GB-Wavenet-D_MALE\",\"en-IN-Wavenet-A_FEMALE\",\"en-IN-Wavenet-B_MALE\",\"en-IN-Wavenet-C_MALE\",\"en-US-Wavenet-G_FEMALE\",\"en-US-Wavenet-H_FEMALE\",\"en-US-Wavenet-I_MALE\",\"en-US-Wavenet-J_MALE\",\"en-US-Wavenet-A_MALE\",\"en-US-Wavenet-B_MALE\",\"en-US-Wavenet-C_FEMALE\",\"en-US-Wavenet-D_MALE\",\"en-US-Wavenet-E_FEMALE\",\"en-US-Wavenet-F_FEMALE\"]\n",
        "p1_speaking_rate = 1 #@param {type:\"slider\", min:0.25, max:4, step:0.05}\n",
        "p1_pitch = 0 #@param {type:\"slider\", min:-20, max:20, step:1}\n",
        "p1_pause = 10 #@param {type:\"slider\", min:0, max:2000, step:10}\n",
        "\n",
        "#@markdown <hr size=\"1\" color=\"#666\"/>\n",
        "\n",
        "#@markdown ###Individual #2\n",
        "p2_voice = \"en-IN-Wavenet-D_FEMALE\" #@param [\"en-GB-Wavenet-F_FEMALE\",\"en-IN-Wavenet-D_FEMALE\",\"en-AU-Wavenet-A_FEMALE\",\"en-AU-Wavenet-B_MALE\",\"en-AU-Wavenet-C_FEMALE\",\"en-AU-Wavenet-D_MALE\",\"en-GB-Wavenet-A_FEMALE\",\"en-GB-Wavenet-B_MALE\",\"en-GB-Wavenet-C_FEMALE\",\"en-GB-Wavenet-D_MALE\",\"en-IN-Wavenet-A_FEMALE\",\"en-IN-Wavenet-B_MALE\",\"en-IN-Wavenet-C_MALE\",\"en-US-Wavenet-G_FEMALE\",\"en-US-Wavenet-H_FEMALE\",\"en-US-Wavenet-I_MALE\",\"en-US-Wavenet-J_MALE\",\"en-US-Wavenet-A_MALE\",\"en-US-Wavenet-B_MALE\",\"en-US-Wavenet-C_FEMALE\",\"en-US-Wavenet-D_MALE\",\"en-US-Wavenet-E_FEMALE\",\"en-US-Wavenet-F_FEMALE\"]\n",
        "p2_speaking_rate = 1 #@param {type:\"slider\", min:0.25, max:4, step:0.05}\n",
        "p2_pitch = 0 #@param {type:\"slider\", min:-20, max:20, step:1}\n",
        "p2_pause = 70 #@param {type:\"slider\", min:0, max:2000, step:10}\n",
        "\n",
        "#@markdown <hr size=\"1\" color=\"#666\"/>\n",
        "\n",
        "\n",
        "\n",
        "dialogue_txt = drive_root+dialogue_txt\n",
        "p1_voice = p1_voice.split('_')[0]\n",
        "p2_voice = p2_voice.split('_')[0]\n",
        "\n",
        "names = []\n",
        "langs = []\n",
        "gends = []\n",
        "for voice in en_voices:\n",
        "  if voice[1] == p1_voice or voice[1] == p2_voice:\n",
        "    names.append(voice[1])\n",
        "    langs.append(voice[0][0])\n",
        "    gends.append(voice[2])\n",
        "\n",
        "# Empty tmp\n",
        "!rm {tmp}*\n",
        "\n",
        "# Parse dialogue\n",
        "dlg = []\n",
        "dialogue = []\n",
        "aline = ''\n",
        "if format == 'dialogue_with_names':\n",
        "  with open(dialogue_txt, 'r') as f_in:\n",
        "    dialogue = list(line for line in (l.strip() for l in f_in) if line)\n",
        "  for i, line in enumerate(dialogue):\n",
        "    if ':' in line:\n",
        "      aline = line.split(':')[1].replace('\\n', '').replace(\"'\", r\"\\\\'\").replace('\\\\\\\\', '\\\\').strip()\n",
        "      if (i < len(dialogue)-1 and ':' in dialogue[i+1]) or (i >= len(dialogue)-1):\n",
        "        dlg.append(aline)\n",
        "    else:\n",
        "      aline = aline+' '+line\n",
        "      aline = aline.replace('\\n', '').replace(\"'\", r\"\\\\'\").replace('\\\\\\\\', '\\\\').strip()\n",
        "      if (i < len(dialogue)-1 and ':' in dialogue[i+1]) or (i >= len(dialogue)-1):\n",
        "        dlg.append(aline)\n",
        "  \n",
        "if format == 'question_and_answer':\n",
        "  dialogue = open(dialogue_txt, 'r').readlines()\n",
        "  for i, line in enumerate(dialogue):\n",
        "    if len(line) > 1:\n",
        "      aline = aline+' '+line\n",
        "      aline = aline.replace('\\n', '').replace(\"'\", r\"\\\\'\").replace('\\\\\\\\', '\\\\').strip()\n",
        "    else:\n",
        "      dlg.append(aline)\n",
        "      aline = ''\n",
        "  dlg.append(dialogue[-1])\n",
        "\n",
        "dialogue = [dlg[::2], dlg[1::2]]\n",
        "\n",
        "# Get audio\n",
        "if use_curl:\n",
        "  op(c.ok, 'Using command line')\n",
        "  for i, repla in enumerate(dlg):\n",
        "    if i % 2 == 0:\n",
        "      #first person\n",
        "      vname = names[0]\n",
        "      vlang = langs[0]\n",
        "      vgend = gends[0]\n",
        "      vrate = p1_speaking_rate\n",
        "      vpitc = p1_pitch\n",
        "      pause = p1_pause\n",
        "    else:\n",
        "      #second person\n",
        "      vname = names[1]\n",
        "      vlang = langs[1]\n",
        "      vgend = gends[1]\n",
        "      vrate = p2_speaking_rate\n",
        "      vpitc = p2_pitch\n",
        "      pause = p2_pause\n",
        "    input_json = \"{'input':{'text':'\"+str(repla)+\"'},'voice':{'languageCode':'\"+str(vlang)+\"','name':'\"+str(vname)+\"','ssmlGender':'\"+str(vgend)+\"'},'audioConfig':{'speaking_rate': '\"+str(vrate)+\"', 'pitch': '\"+str(vpitc)+\"', 'audioEncoding':'LINEAR16'}}\"\n",
        "    print('\\n')\n",
        "    op(c.title, str(i), repla)\n",
        "    !curl -H \"Authorization: Bearer $(gcloud auth application-default print-access-token)\" -H \"Content-Type: application/json; charset=utf-8\" --data \"{input_json}\" \"https://texttospeech.googleapis.com/v1/text:synthesize\" > temp.json\n",
        "    with open('temp.json') as fp:\n",
        "      for ii, line in enumerate(fp):\n",
        "        if ii == 1:\n",
        "          audio_content = line.replace('\"audioContent\": \"', '').replace('\"', '').strip()\n",
        "    writeFile('base64-temp.txt', audio_content)\n",
        "    wav_file = tmp+'decoded-'+str(i).zfill(4)+'.wav'\n",
        "    !base64 base64-temp.txt -d > {wav_file}\n",
        "\n",
        "    pvar = pause * pause_variation if odds(0.5) else abs(pause * pause_variation)\n",
        "    pause = pause + pvar\n",
        "    save(generate_silence(pause/1000), tmp+'decoded-'+str(i).zfill(4)+'_pause.wav')\n",
        "  \n",
        "  all_audio = []\n",
        "  for audio_file in list_audio(tmp):\n",
        "    all_audio.append(librosa.load(audio_file, sr=global_sr)[0])\n",
        "  all_audio = np.concatenate(all_audio)\n",
        "  output_wav = path_dir(dialogue_txt)+basename(dialogue_txt)+'.wav'\n",
        "  save(all_audio, output_wav)\n",
        "  output.clear()\n",
        "  op(c.ok, 'File saved as', output_wav.replace(drive_root, ''))\n",
        "  print('\\n')\n",
        "  audio_player(output_wav)\n",
        "else:\n",
        "  \n",
        "  ## Update to Python API whenever it works:\n",
        "  \n",
        "  # from google.cloud import texttospeech\n",
        "  # client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "  # synthesis_input = texttospeech.SynthesisInput(text=\"Hello, World!\")\n",
        "  # voice = texttospeech.VoiceSelectionParams(\n",
        "  #     language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
        "  # )\n",
        "\n",
        "  # audio_config = texttospeech.AudioConfig(\n",
        "  #     audio_encoding=texttospeech.AudioEncoding.LINEAR16\n",
        "  # )\n",
        "\n",
        "  # response = client.synthesize_speech(\n",
        "  #     input=synthesis_input, voice=voice, audio_config=audio_config\n",
        "  # )\n",
        "\n",
        "  # with open('out.wav', \"wb\") as out:\n",
        "  #     out.write(response.audio_content)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}